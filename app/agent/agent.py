"""
STARGENT AI ì—ì´ì „íŠ¸ ì‹¤í–‰ ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ ê° AI ì—ì´ì „íŠ¸ì˜ ì‹¤í–‰ê³¼ ìƒí˜¸ì‘ìš©ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.
í”„ë¡¬í”„íŠ¸ ë¡œë”©, LLM í˜¸ì¶œ, ë„êµ¬ ì‚¬ìš©, ì—ëŸ¬ í•¸ë“¤ë§ì„ í†µí•©ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬
ê° ì—ì´ì „íŠ¸ê°€ ìì‹ ì˜ ì—­í• ì„ íš¨ê³¼ì ìœ¼ë¡œ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
    - í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë”© ë° ì»¨í…ìŠ¤íŠ¸ ì£¼ì…
    - OpenAI GPT ëª¨ë¸ê³¼ì˜ ìƒí˜¸ì‘ìš©
    - Function Callingì„ í†µí•œ ë„êµ¬ ì‚¬ìš©
    - ì—ëŸ¬ í•¸ë“¤ë§ ë° ì¬ì‹œë„ ë¡œì§
    - ê° ì—ì´ì „íŠ¸ë³„ íŠ¹í™”ëœ ì‹¤í–‰ í•¨ìˆ˜

ì„¤ê³„ ì² í•™:
    - ê° ì—ì´ì „íŠ¸ëŠ” ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ ê°€ëŠ¥
    - ì¼ê´€ëœ ì…ë ¥/ì¶œë ¥ í˜•ì‹ ìœ ì§€
    - ê²¬ê³ í•œ ì—ëŸ¬ ì²˜ë¦¬ë¡œ ì„œë¹„ìŠ¤ ì•ˆì •ì„± í™•ë³´
    - í™•ì¥ ê°€ëŠ¥í•œ êµ¬ì¡°ë¡œ ìƒˆë¡œìš´ ì—ì´ì „íŠ¸ ì¶”ê°€ ìš©ì´
"""

import os
import json
import openai
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
import time
from .model_class import UserContexts, AgentContexts, AgentOutput, AgentPlan
from .tools import AGENT_TOOLS, TOOL_FUNCTIONS

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

def load_prompt(agent_name: str) -> str:
    """
    ì—ì´ì „íŠ¸ë³„ í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ë¡œë”©í•©ë‹ˆë‹¤.
    
    prompts/ ë””ë ‰í† ë¦¬ì—ì„œ í•´ë‹¹ ì—ì´ì „íŠ¸ì˜ ë§ˆí¬ë‹¤ìš´ í”„ë¡¬í”„íŠ¸ë¥¼ ì½ì–´ì™€ì„œ
    ë¬¸ìì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤. íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        agent_name (str): ì—ì´ì „íŠ¸ ì´ë¦„ (manager, bibi, kiki, ager, ramu, coli)
        
    Returns:
        str: í”„ë¡¬í”„íŠ¸ ë‚´ìš©
        
    ì‚¬ìš© ì˜ˆì‹œ:
        >>> prompt = load_prompt("bibi")
        >>> print("í”„ë¡¬í”„íŠ¸ ê¸¸ì´:", len(prompt))
    """
    try:
        # í˜„ì¬ íŒŒì¼ ìœ„ì¹˜ì—ì„œ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì°¾ê¸°
        current_file = Path(__file__)
        project_root = current_file.parent.parent.parent  # app/agent/agent.py -> project_root
        prompt_path = project_root / "prompts" / f"{agent_name}.md"
        
        if prompt_path.exists():
            with open(prompt_path, 'r', encoding='utf-8') as f:
                prompt_content = f.read()
            print(f"âœ… í”„ë¡¬í”„íŠ¸ ë¡œë”© ì™„ë£Œ: {agent_name}.md ({len(prompt_content)} chars)")
            return prompt_content
        else:
            print(f"âš ï¸ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì—†ìŒ: {prompt_path}")
            return f"ë‹¹ì‹ ì€ {agent_name} ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìš”ì²­ì— ë„ì›€ì´ ë˜ëŠ” ì‘ë‹µì„ ì œê³µí•´ì£¼ì„¸ìš”."
            
    except Exception as e:
        print(f"âŒ í”„ë¡¬í”„íŠ¸ ë¡œë”© ì‹¤íŒ¨ ({agent_name}): {e}")
        return f"ë‹¹ì‹ ì€ {agent_name} ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìš”ì²­ì— ë„ì›€ì´ ë˜ëŠ” ì‘ë‹µì„ ì œê³µí•´ì£¼ì„¸ìš”."

def safe_llm_call_with_retry(messages: List[Dict], tools: Optional[List] = None, max_retries: int = 2) -> Optional[Dict]:
    """
    LLM í˜¸ì¶œì„ ì•ˆì „í•˜ê²Œ ì‹¤í–‰í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
    
    ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ë‚˜ API ì˜¤ë¥˜ ì‹œ ìë™ìœ¼ë¡œ ì¬ì‹œë„í•˜ë©°,
    ê°ì¢… ì˜ˆì™¸ ìƒí™©ì„ ì ì ˆíˆ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    
    Args:
        messages (List[Dict]): ëŒ€í™” ë©”ì‹œì§€ ëª©ë¡
        tools (Optional[List]): ì‚¬ìš©í•  ë„êµ¬ ëª©ë¡
        max_retries (int): ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
        
    Returns:
        Optional[Dict]: API ì‘ë‹µ ë˜ëŠ” None (ì‹¤íŒ¨ ì‹œ)
        
    ì‚¬ìš© ì˜ˆì‹œ:
        >>> messages = [{"role": "user", "content": "ì•ˆë…•í•˜ì„¸ìš”"}]
        >>> response = safe_llm_call_with_retry(messages)
        >>> if response:
        ...     print("ì‘ë‹µ:", response.choices[0].message.content)
    """
    for attempt in range(max_retries + 1):
        try:
            call_params = {
                "model": "gpt-4.1-mini",
                "messages": messages,
                "temperature": 0.7,
                "max_tokens": 2000
            }
            
            # ë„êµ¬ê°€ ìˆëŠ” ê²½ìš° ì¶”ê°€
            if tools:
                call_params["tools"] = tools
                call_params["tool_choice"] = "auto"
            
            response = client.chat.completions.create(**call_params)
            return response
            
        except openai.APIError as e:
            error_msg = f"OpenAI API ì˜¤ë¥˜: {e}"
        except openai.RateLimitError:
            error_msg = "API í˜¸ì¶œ í•œë„ ì´ˆê³¼"
        except openai.APIConnectionError:
            error_msg = "API ì—°ê²° ì˜¤ë¥˜"
        except Exception as e:
            error_msg = f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}"
        
        if attempt == max_retries:
            print(f"âŒ LLM í˜¸ì¶œ ìµœì¢… ì‹¤íŒ¨: {error_msg}")
            return None
        
        print(f"âš ï¸ LLM í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}), ì¬ì‹œë„: {error_msg}")
        time.sleep(1)  # 1ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„
    
    return None

def execute_tools_if_needed(response, available_tools: Dict[str, Any]) -> Tuple[str, List[Dict]]:
    """
    LLM ì‘ë‹µì—ì„œ ë„êµ¬ í˜¸ì¶œì´ í•„ìš”í•œ ê²½ìš° ì‹¤í–‰í•©ë‹ˆë‹¤.
    
    OpenAI Function Calling ê²°ê³¼ë¥¼ íŒŒì‹±í•˜ì—¬ í•´ë‹¹ ë„êµ¬ë¥¼ ì‹¤í–‰í•˜ê³ ,
    ê²°ê³¼ë¥¼ ë‹¤ì‹œ LLMì— ì „ë‹¬í•  ìˆ˜ ìˆë„ë¡ ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    Args:
        response: OpenAI API ì‘ë‹µ ê°ì²´
        available_tools (Dict[str, Any]): ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ í•¨ìˆ˜ë“¤
        
    Returns:
        Tuple[str, List[Dict]]: (ì‘ë‹µ í…ìŠ¤íŠ¸, ì¶”ê°€ ë©”ì‹œì§€ ëª©ë¡)
        
    ì‚¬ìš© ì˜ˆì‹œ:
        >>> response = client.chat.completions.create(...)
        >>> content, additional_messages = execute_tools_if_needed(response, TOOL_FUNCTIONS)
        >>> print("ìµœì¢… ì‘ë‹µ:", content)
    """
    message = response.choices[0].message
    additional_messages = []
    
    # ë„êµ¬ í˜¸ì¶œì´ ìˆëŠ” ê²½ìš°
    if hasattr(message, 'tool_calls') and message.tool_calls:
        # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì¶”ê°€
        additional_messages.append({
            "role": "assistant",
            "content": message.content,
            "tool_calls": [
                {
                    "id": tool_call.id,
                    "type": tool_call.type,
                    "function": {
                        "name": tool_call.function.name,
                        "arguments": tool_call.function.arguments
                    }
                } for tool_call in message.tool_calls
            ]
        })
        
        # ê° ë„êµ¬ í˜¸ì¶œ ì‹¤í–‰
        for tool_call in message.tool_calls:
            function_name = tool_call.function.name
            
            try:
                # í•¨ìˆ˜ ì¸ì íŒŒì‹±
                function_args = json.loads(tool_call.function.arguments)
                
                # ë„êµ¬ ì‹¤í–‰
                if function_name in available_tools:
                    print(f"ğŸ”§ ë„êµ¬ ì‹¤í–‰: {function_name}({function_args})")
                    function_response = available_tools[function_name](**function_args)
                else:
                    function_response = f"ì˜¤ë¥˜: ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬ '{function_name}'"
                
            except json.JSONDecodeError:
                function_response = f"ì˜¤ë¥˜: {function_name}ì˜ ì¸ì íŒŒì‹± ì‹¤íŒ¨"
            except Exception as e:
                function_response = f"ì˜¤ë¥˜: {function_name} ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ - {str(e)}"
            
            # ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë©”ì‹œì§€ë¡œ ì¶”ê°€
            additional_messages.append({
                "role": "tool",
                "tool_call_id": tool_call.id,
                "content": function_response
            })
        
        return message.content or "", additional_messages
    
    # ë„êµ¬ í˜¸ì¶œì´ ì—†ëŠ” ê²½ìš° ì¼ë°˜ ì‘ë‹µ ë°˜í™˜
    return message.content or "", additional_messages

def create_context_prompt(user_ctx: UserContexts, agent_ctx: AgentContexts, base_prompt: str) -> str:
    """
    ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ì— ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ì£¼ì…í•˜ì—¬ ì™„ì„±ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    ì‚¬ìš©ì ì •ë³´, ì´ì „ ëŒ€í™” ê¸°ë¡, ë‹¤ë¥¸ ì—ì´ì „íŠ¸ë“¤ì˜ ì‘ì—… ê²°ê³¼ ë“±ì„
    í”„ë¡¬í”„íŠ¸ì— ìì—°ìŠ¤ëŸ½ê²Œ í†µí•©í•˜ì—¬ ê°œì¸í™”ëœ ì‘ë‹µì´ ê°€ëŠ¥í•˜ë„ë¡ í•©ë‹ˆë‹¤.
    
    Args:
        user_ctx (UserContexts): ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸
        agent_ctx (AgentContexts): ì—ì´ì „íŠ¸ ì»¨í…ìŠ¤íŠ¸  
        base_prompt (str): ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        
    Returns:
        str: ì»¨í…ìŠ¤íŠ¸ê°€ ì£¼ì…ëœ ì™„ì„± í”„ë¡¬í”„íŠ¸
    """
    context_info = "\n\n=== ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ===\n"
    
    # ì‚¬ìš©ì ì •ë³´ ì¶”ê°€
    if user_ctx.user_info:
        context_info += f"\nã€ì‚¬ìš©ì ì •ë³´ã€‘\n"
        for key, value in user_ctx.user_info.items():
            context_info += f"- {key}: {value}\n"
    
    # ìµœê·¼ ëŒ€í™” ê¸°ë¡ ì¶”ê°€ (ìµœëŒ€ 5ê°œ)
    if user_ctx.chat_history:
        context_info += f"\nã€ìµœê·¼ ëŒ€í™” ê¸°ë¡ã€‘\n"
        recent_chats = user_ctx.chat_history[-5:]  # ìµœê·¼ 5ê°œë§Œ
        for chat in recent_chats:
            role_name = "ì‚¬ìš©ì" if chat['role'] == 'user' else "AI"
            context_info += f"- {role_name}: {chat['content'][:100]}{'...' if len(chat['content']) > 100 else ''}\n"
    
    # ì´ì „ ì—ì´ì „íŠ¸ ì‘ì—… ê²°ê³¼ ì¶”ê°€
    if agent_ctx.agent_output:
        context_info += f"\nã€ì´ì „ ì—ì´ì „íŠ¸ ì‘ì—… ê²°ê³¼ã€‘\n"
        for i, output in enumerate(agent_ctx.agent_output):
            agent_name = agent_ctx.agent_id_history[i] if i < len(agent_ctx.agent_id_history) else f"Agent{i}"
            context_info += f"- {agent_name}: {output.progress_description}\n"
            context_info += f"  ê²°ê³¼: {output.output[:200]}{'...' if len(output.output) > 200 else ''}\n"
    
    # í˜„ì¬ ì‘ì—… ë‹¨ê³„ ì •ë³´
    context_info += f"\nã€ì‘ì—… ì§„í–‰ ìƒí™©ã€‘\n"
    context_info += f"- í˜„ì¬ ë‹¨ê³„: {agent_ctx.current_step + 1}/{agent_ctx.total_step}\n"
    context_info += f"- ì™„ë£Œëœ ì—ì´ì „íŠ¸: {', '.join(agent_ctx.agent_id_history) if agent_ctx.agent_id_history else 'ì—†ìŒ'}\n"
    
    # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ì™€ ì»¨í…ìŠ¤íŠ¸ ê²°í•©
    complete_prompt = base_prompt + context_info + "\n\nìœ„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ìš”ì²­ì— ì ì ˆíˆ ì‘ë‹µí•´ì£¼ì„¸ìš”."
    
    return complete_prompt

# =============================================================================
# ê° ì—ì´ì „íŠ¸ë³„ ì‹¤í–‰ í•¨ìˆ˜ë“¤
# =============================================================================

def execute_manager(user_ctx: UserContexts, agent_ctx: AgentContexts) -> AgentPlan:
    """
    ë§¤ë‹ˆì € ì—ì´ì „íŠ¸ë¥¼ ì‹¤í–‰í•˜ì—¬ ì‘ì—… ê³„íšì„ ìˆ˜ë¦½í•©ë‹ˆë‹¤.
    
    ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ì–´ë–¤ ì—ì´ì „íŠ¸ë“¤ì´ ì–´ë–¤ ìˆœì„œë¡œ ì‘ì—…í• ì§€ë¥¼
    ê²°ì •í•˜ê³ , êµ¬ì²´ì ì¸ ì‹¤í–‰ ê³„íšì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        user_ctx (UserContexts): ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸
        agent_ctx (AgentContexts): ì—ì´ì „íŠ¸ ì»¨í…ìŠ¤íŠ¸
        
    Returns:
        AgentPlan: ìƒì„±ëœ ì‘ì—… ê³„íš
        
    ì‚¬ìš© ì˜ˆì‹œ:
        >>> plan = execute_manager(user_ctx, agent_ctx)
        >>> print(f"ì´ {plan.total_steps}ë‹¨ê³„ ì‘ì—… ê³„íš")
        >>> for i, step in enumerate(plan.plans):
        ...     print(f"{i+1}. {step['agent_name']}: {step['description']}")
    """
    try:
        # ë§¤ë‹ˆì € í”„ë¡¬í”„íŠ¸ ë¡œë”©
        base_prompt = load_prompt("manager")
        
        # ìµœê·¼ ì‚¬ìš©ì ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°
        last_user_message = ""
        if user_ctx.chat_history:
            for chat in reversed(user_ctx.chat_history):
                if chat['role'] == 'user':
                    last_user_message = chat['content']
                    break
        
        # ì™„ì„±ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±
        complete_prompt = create_context_prompt(user_ctx, agent_ctx, base_prompt)
        
        # PLAN ìš”ì²­ ë©”ì‹œì§€ êµ¬ì„±
        plan_request = f"""
ì‚¬ìš©ì ìš”ì²­: "{last_user_message}"

ìœ„ ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì‘ì—… ê³„íš(PLAN)ì„ ìˆ˜ë¦½í•´ì£¼ì„¸ìš”.
ë°ëª¨ í™˜ê²½ì´ë¯€ë¡œ ìµœëŒ€ 3ë‹¨ê³„ê¹Œì§€ë§Œ ê³„íší•˜ê³ , ì£¼ë¡œ Chat ëª¨ë“œë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "total_steps": ìˆ«ì,
    "plans": [
        {{
            "agent_name": "ì—ì´ì „íŠ¸ëª…",
            "description": "êµ¬ì²´ì ì¸ ì‘ì—… ì„¤ëª…", 
            "tool_recommendation": ["ë„êµ¬1", "ë„êµ¬2"]
        }}
    ],
    "mode": "chat"
}}
"""
        
        messages = [
            {"role": "system", "content": complete_prompt},
            {"role": "user", "content": plan_request}
        ]
        
        # LLM í˜¸ì¶œ
        response = safe_llm_call_with_retry(messages)
        
        if response is None:
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ê³„íš ë°˜í™˜
            fallback_plan = AgentPlan(
                total_steps=1,
                plans=[{
                    "agent_name": "ë¹„ë¹„",
                    "description": "ì‚¬ìš©ì ìš”ì²­ì— ëŒ€í•œ ê¸°ë³¸ì ì¸ ì‘ë‹µ ì œê³µ",
                    "tool_recommendation": []
                }],
                mode="chat"
            )
            print("âš ï¸ ë§¤ë‹ˆì € ì‹¤í–‰ ì‹¤íŒ¨, ê¸°ë³¸ ê³„íš ì‚¬ìš©")
            return fallback_plan
        
        # JSON íŒŒì‹± ì‹œë„
        try:
            response_content = response.choices[0].message.content
            # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°)
            if "```json" in response_content:
                json_start = response_content.find("```json") + 7
                json_end = response_content.find("```", json_start)
                response_content = response_content[json_start:json_end].strip()
            elif "```" in response_content:
                json_start = response_content.find("```") + 3
                json_end = response_content.find("```", json_start)
                response_content = response_content[json_start:json_end].strip()
            
            plan_data = json.loads(response_content)
            
            # AgentPlan ê°ì²´ ìƒì„±
            plan = AgentPlan(
                total_steps=plan_data.get("total_steps", 1),
                plans=plan_data.get("plans", []),
                mode=plan_data.get("mode", "chat")
            )
            
            print(f"âœ… ë§¤ë‹ˆì € ê³„íš ìˆ˜ë¦½ ì™„ë£Œ: {plan.total_steps}ë‹¨ê³„, {plan.mode} ëª¨ë“œ")
            return plan
            
        except (json.JSONDecodeError, KeyError) as e:
            print(f"âš ï¸ ë§¤ë‹ˆì € ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì‘ë‹µ ë‚´ìš© ê¸°ë°˜ ê°„ë‹¨í•œ ê³„íš ìƒì„±
            if "í‚¤í‚¤" in response.choices[0].message.content:
                agent_name = "í‚¤í‚¤"
            elif "ì•„ê±°" in response.choices[0].message.content:
                agent_name = "ì•„ê±°"
            elif "ë¼ë¬´" in response.choices[0].message.content:
                agent_name = "ë¼ë¬´"
            elif "ì½œë¦¬" in response.choices[0].message.content:
                agent_name = "ì½œë¦¬"
            else:
                agent_name = "ë¹„ë¹„"
            
            fallback_plan = AgentPlan(
                total_steps=1,
                plans=[{
                    "agent_name": agent_name,
                    "description": "ì‚¬ìš©ì ìš”ì²­ ì²˜ë¦¬",
                    "tool_recommendation": []
                }],
                mode="chat"
            )
            return fallback_plan
            
    except Exception as e:
        print(f"âŒ ë§¤ë‹ˆì € ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ê³„íš
        return AgentPlan(
            total_steps=1,
            plans=[{
                "agent_name": "ë¹„ë¹„",
                "description": "ì˜¤ë¥˜ ìƒí™©ì—ì„œì˜ ê¸°ë³¸ ì‘ë‹µ",
                "tool_recommendation": []
            }],
            mode="chat"
        )

def execute_agent(agent_name: str, user_ctx: UserContexts, agent_ctx: AgentContexts) -> AgentOutput:
    """
    ì§€ì •ëœ ì—ì´ì „íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
    
    ì—ì´ì „íŠ¸ë³„ í”„ë¡¬í”„íŠ¸ë¥¼ ë¡œë”©í•˜ê³ , í•„ìš”í•œ ë„êµ¬ë“¤ì„ ì œê³µí•˜ì—¬
    ì‚¬ìš©ìì˜ ìš”ì²­ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤. ëª¨ë“  ì—ì´ì „íŠ¸ê°€ ê³µí†µìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ”
    í•µì‹¬ ì‹¤í–‰ ë¡œì§ì…ë‹ˆë‹¤.
    
    Args:
        agent_name (str): ì‹¤í–‰í•  ì—ì´ì „íŠ¸ ì´ë¦„
        user_ctx (UserContexts): ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸
        agent_ctx (AgentContexts): ì—ì´ì „íŠ¸ ì»¨í…ìŠ¤íŠ¸
        
    Returns:
        AgentOutput: ì—ì´ì „íŠ¸ ì‹¤í–‰ ê²°ê³¼
        
    ì‚¬ìš© ì˜ˆì‹œ:
        >>> result = execute_agent("í‚¤í‚¤", user_ctx, agent_ctx)
        >>> print(f"ì‘ì—… ì™„ë£Œ: {result.progress_description}")
        >>> print(f"ê²°ê³¼: {result.output}")
    """
    try:
        print(f"ğŸ¤– {agent_name} ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹œì‘")
        
        # í”„ë¡¬í”„íŠ¸ ë¡œë”©
        base_prompt = load_prompt(agent_name.lower())
        
        # ì»¨í…ìŠ¤íŠ¸ê°€ ì£¼ì…ëœ ì™„ì„± í”„ë¡¬í”„íŠ¸ ìƒì„±
        complete_prompt = create_context_prompt(user_ctx, agent_ctx, base_prompt)
        
        # ìµœê·¼ ì‚¬ìš©ì ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°
        last_user_message = ""
        if user_ctx.chat_history:
            for chat in reversed(user_ctx.chat_history):
                if chat['role'] == 'user':
                    last_user_message = chat['content']
                    break
        
        # ë©”ì‹œì§€ êµ¬ì„±
        messages = [
            {"role": "system", "content": complete_prompt},
            {"role": "user", "content": last_user_message}
        ]
        
        # ì—ì´ì „íŠ¸ë³„ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ í™•ì¸
        available_tools = AGENT_TOOLS.get(agent_name, [])
        
        # ì²« ë²ˆì§¸ LLM í˜¸ì¶œ
        response = safe_llm_call_with_retry(messages, available_tools if available_tools else None)
        
        if response is None:
            return AgentOutput(
                final_output=True,
                progress_description=f"{agent_name} ì‹¤í–‰ ì‹¤íŒ¨",
                output="ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì„œë¹„ìŠ¤ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            )
        
        # ë„êµ¬ í˜¸ì¶œ ì²˜ë¦¬
        content, additional_messages = execute_tools_if_needed(response, TOOL_FUNCTIONS)
        
        # ë„êµ¬ í˜¸ì¶œì´ ìˆì—ˆë‹¤ë©´ ìµœì¢… ì‘ë‹µ ìƒì„±
        if additional_messages:
            final_messages = messages + additional_messages
            final_response = safe_llm_call_with_retry(final_messages)
            
            if final_response:
                final_content = final_response.choices[0].message.content
            else:
                final_content = content or "ë„êµ¬ ì‹¤í–‰ì€ ì™„ë£Œë˜ì—ˆì§€ë§Œ ìµœì¢… ì‘ë‹µ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
        else:
            final_content = content
        
        # ìµœì¢… ë‹¨ê³„ì¸ì§€ í™•ì¸
        is_final = agent_ctx.current_step + 1 >= agent_ctx.total_step
        
        # AgentOutput ìƒì„±
        result = AgentOutput(
            final_output=is_final,
            progress_description=f"{agent_name}ì˜ ì‘ì—… ì™„ë£Œ",
            output=final_content or "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        )
        
        print(f"âœ… {agent_name} ì—ì´ì „íŠ¸ ì‹¤í–‰ ì™„ë£Œ")
        return result
        
    except Exception as e:
        print(f"âŒ {agent_name} ì—ì´ì „íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        return AgentOutput(
            final_output=True,
            progress_description=f"{agent_name} ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ",
            output=f"ì£„ì†¡í•©ë‹ˆë‹¤. {agent_name} ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        )

# í¸ì˜ë¥¼ ìœ„í•œ ê°œë³„ ì—ì´ì „íŠ¸ ì‹¤í–‰ í•¨ìˆ˜ë“¤
def execute_bibi(user_ctx: UserContexts, agent_ctx: AgentContexts) -> AgentOutput:
    """ë¹„ë¹„ ì—ì´ì „íŠ¸ ì‹¤í–‰"""
    return execute_agent("ë¹„ë¹„", user_ctx, agent_ctx)

def execute_kiki(user_ctx: UserContexts, agent_ctx: AgentContexts) -> AgentOutput:
    """í‚¤í‚¤ ì—ì´ì „íŠ¸ ì‹¤í–‰"""
    return execute_agent("í‚¤í‚¤", user_ctx, agent_ctx)

def execute_ager(user_ctx: UserContexts, agent_ctx: AgentContexts) -> AgentOutput:
    """ì•„ê±° ì—ì´ì „íŠ¸ ì‹¤í–‰"""
    return execute_agent("ì•„ê±°", user_ctx, agent_ctx)

def execute_ramu(user_ctx: UserContexts, agent_ctx: AgentContexts) -> AgentOutput:
    """ë¼ë¬´ ì—ì´ì „íŠ¸ ì‹¤í–‰"""
    return execute_agent("ë¼ë¬´", user_ctx, agent_ctx)

def execute_coli(user_ctx: UserContexts, agent_ctx: AgentContexts) -> AgentOutput:
    """ì½œë¦¬ ì—ì´ì „íŠ¸ ì‹¤í–‰"""
    return execute_agent("ì½œë¦¬", user_ctx, agent_ctx)

# ì—ì´ì „íŠ¸ ì´ë¦„ê³¼ ì‹¤í–‰ í•¨ìˆ˜ ë§¤í•‘
AGENT_EXECUTORS = {
    "ë¹„ë¹„": execute_bibi,
    "í‚¤í‚¤": execute_kiki, 
    "ì•„ê±°": execute_ager,
    "ë¼ë¬´": execute_ramu,
    "ì½œë¦¬": execute_coli
}

def execute_plan(plan: AgentPlan, user_ctx: UserContexts) -> AgentContexts:
    """
    ì‘ì—… ê³„íšì— ë”°ë¼ ì—ì´ì „íŠ¸ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.
    
    ë§¤ë‹ˆì €ê°€ ìˆ˜ë¦½í•œ ê³„íšì— ë”°ë¼ ê° ì—ì´ì „íŠ¸ë¥¼ ìˆœì„œëŒ€ë¡œ í˜¸ì¶œí•˜ê³ ,
    ê° ë‹¨ê³„ì˜ ê²°ê³¼ë¥¼ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì „ë‹¬í•˜ì—¬ í˜‘ì—…ì„ êµ¬í˜„í•©ë‹ˆë‹¤.
    
    Args:
        plan (AgentPlan): ì‹¤í–‰í•  ì‘ì—… ê³„íš
        user_ctx (UserContexts): ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸
        
    Returns:
        AgentContexts: ì‹¤í–‰ ê²°ê³¼ê°€ í¬í•¨ëœ ì—ì´ì „íŠ¸ ì»¨í…ìŠ¤íŠ¸
        
    ì‚¬ìš© ì˜ˆì‹œ:
        >>> plan = execute_manager(user_ctx, agent_ctx)
        >>> result_ctx = execute_plan(plan, user_ctx)
        >>> final_output = result_ctx.agent_output[-1]
        >>> print("ìµœì¢… ê²°ê³¼:", final_output.output)
    """
    # ìƒˆë¡œìš´ AgentContexts ìƒì„±
    agent_ctx = AgentContexts(
        total_step=plan.total_steps,
        current_step=0,
        agent_id_history=[],
        agent_output=[]
    )
    
    print(f"ğŸ“‹ ì‘ì—… ê³„íš ì‹¤í–‰ ì‹œì‘: {plan.total_steps}ë‹¨ê³„")
    
    # ê° ë‹¨ê³„ë³„ë¡œ ì—ì´ì „íŠ¸ ì‹¤í–‰
    for step_idx, step_plan in enumerate(plan.plans):
        agent_name = step_plan["agent_name"]
        description = step_plan["description"]
        
        print(f"\nğŸ“ ë‹¨ê³„ {step_idx + 1}/{plan.total_steps}: {agent_name} - {description}")
        
        # í•´ë‹¹ ì—ì´ì „íŠ¸ ì‹¤í–‰
        if agent_name in AGENT_EXECUTORS:
            result = AGENT_EXECUTORS[agent_name](user_ctx, agent_ctx)
        else:
            print(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ì—ì´ì „íŠ¸: {agent_name}, ë¹„ë¹„ë¡œ ëŒ€ì²´")
            result = execute_bibi(user_ctx, agent_ctx)
        
        # ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€
        agent_ctx.add_agent_result(agent_name, result)
        
        print(f"âœ… {agent_name} ì‘ì—… ì™„ë£Œ: {result.progress_description}")
    
    print(f"ğŸ‰ ì „ì²´ ì‘ì—… ê³„íš ì‹¤í–‰ ì™„ë£Œ!")
    return agent_ctx

# ëª¨ë“ˆ í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    print("=== STARGENT ì—ì´ì „íŠ¸ ì‹¤í–‰ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ===")
    
    # í™˜ê²½ í™•ì¸
    if not os.getenv('OPENAI_API_KEY'):
        print("âš ï¸ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ì‹¤ì œ í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        exit()
    
    # í…ŒìŠ¤íŠ¸ìš© ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    user_ctx = UserContexts(
        user_info={
            'name': 'í…ŒìŠ¤íŠ¸ì‚¬ìš©ì',
            'investment_style': 'ì¤‘ë„ì ',
            'portfolio': ['ì‚¼ì„±ì „ì', 'SKí•˜ì´ë‹‰ìŠ¤']
        }
    )
    user_ctx.add_user_message("ì‚¼ì„±ì „ì ì£¼ê°€ ì–´ë•Œ?")
    
    agent_ctx = AgentContexts()
    
    # ë§¤ë‹ˆì € ì‹¤í–‰ í…ŒìŠ¤íŠ¸
    print("\nğŸ§  ë§¤ë‹ˆì € ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸:")
    plan = execute_manager(user_ctx, agent_ctx)
    print(f"ìƒì„±ëœ ê³„íš: {plan.total_steps}ë‹¨ê³„")
    print(plan)
    
    # ê°œë³„ ì—ì´ì „íŠ¸ ì‹¤í–‰ í…ŒìŠ¤íŠ¸ (ë¹„ë¹„)
    print("\nğŸ» ë¹„ë¹„ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸:")
    result = execute_bibi(user_ctx, agent_ctx)
    print(f"ì‹¤í–‰ ê²°ê³¼: {result.progress_description}")
    print(result)
    
    print("\nâœ… ì—ì´ì „íŠ¸ ì‹¤í–‰ ëª¨ë“ˆì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤! ğŸ‰")